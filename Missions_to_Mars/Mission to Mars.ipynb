{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Challenge\n",
    "\n",
    "### By: Carlos Casio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Current google-chrome version is 87.0.4280\n",
      "[WDM] - Get LATEST driver version for 87.0.4280\n",
      "[WDM] - Driver [C:\\Users\\Carlo\\.wdm\\drivers\\chromedriver\\win32\\87.0.4280.88\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "# Executing empty browser with ChromeDriveManager\n",
    "executable_path = {\"executable_path\": ChromeDriverManager().install()}\n",
    "browser = Browser(\"chrome\", **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nasa Mars News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visiting the first site and extracting the html code for the webpage. \n",
    "# The site was loading too fast so I added a match check for a list element, since all the news are listed on these classes.\n",
    "# After it loads, we can continue\n",
    "browser.visit(\"https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest\")\n",
    "browser.is_element_present_by_tag('LI', wait_time=10)\n",
    "html = browser.html\n",
    "soup = bs(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing First image, header and brief from the first News element.\n",
    "# We get the second [1] element for the header because the first one with the same class is not related to any News\n",
    "Header = soup.find_all(\"div\",class_=\"content_title\")[1].text.strip()\n",
    "paragraph =  soup.find(\"div\",class_=\"article_teaser_body\").text.strip()\n",
    "\n",
    "# For the image to work, the prefix is needed so we can join both strings\n",
    "mainpage = \"mars.nasa.gov\"\n",
    "img =  soup.find(\"div\",class_=\"list_image\").find(\"img\")[\"src\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainpage + img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JPL Mars Space Images - Featured Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visiting the second browser and storing the html code\n",
    "browser.visit(\"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\")\n",
    "html = browser.html\n",
    "soup = bs(html, \"html.parser\")\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, we need the main webpage to get the the complete url for the image working.\n",
    "jpl_mainpage = \"jpl.nasa.gov\"\n",
    "\n",
    "# We get the a tag with a unique id, and then we extract the first element containing the href link\n",
    "featured_image = soup.find_all(\"a\", id=\"full_image\")\n",
    "featured_image = jpl_mainpage + featured_image[0][\"data-fancybox-href\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visiting webpage and extracting html code, I use the method \"is text present\" to check if the \"Insight sol\" string is already\n",
    "# there, meaning all the tweets have been loaded correctly, because I had troubles running the whole cell at once\n",
    "browser.visit(\"https://twitter.com/marswxreport?lang=en\")\n",
    "browser.is_text_present('InSight sol', wait_time=10)\n",
    "html = browser.html\n",
    "soup = bs(html, \"html.parser\")\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I create a list to iterate from all the tags and get the text of them\n",
    "article_list = []\n",
    "\n",
    "# Every tweet that contains text has a span tag with a class \"css-901oao\", so first I find all the tags with this specifications\n",
    "articles = soup.find_all(\"span\", class_=\"css-901oao\")\n",
    "\n",
    "# Then I loop to obtain the text of each class with that name\n",
    "for x in articles:\n",
    "    article_list.append(x.text)\n",
    "article_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, as I only need the latest tweet related to weather, I noticed they all start with \"InSight sol\" string,\n",
    "# so I compare the first 11 characters (lenght of that string) to the text itself, bringing the result I want\n",
    "for y in article_list:\n",
    "    if y[:11] == \"InSight sol\":\n",
    "        latest_tweet = y\n",
    "        print(latest_tweet)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visiting the URL and obtaining the HTML code\n",
    "browser.visit(\"https://space-facts.com/mars/\")\n",
    "html = browser.html\n",
    "soup = bs(html, \"html.parser\")\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping table by its id\n",
    "table = soup.find(\"table\", id=\"tablepress-p-mars\")\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating through each table data from column 1 and column 2, adding to a list and returning a dataframe\n",
    "col1 = table.find_all(\"td\", class_=\"column-1\")\n",
    "Description = []\n",
    "for x in col1:\n",
    "    Description.append(x.text)\n",
    "    \n",
    "Description\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating through the same table but for column 2\n",
    "Value = []\n",
    "col2 = table.find_all(\"td\", class_=\"column-2\")\n",
    "for y in col2:\n",
    "    Value.append(y.text)\n",
    "    \n",
    "Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting lists to DataFrame, so I can send it as an HTML table (without index) to be used later\n",
    "mars_table_df = pd.DataFrame({\"Description\":Description,\n",
    "             \"Value\":Value})\n",
    "mars_table_df.to_html(\"table.html\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Visiting the webpage and getting the HTML code\n",
    "browser.visit(\"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\")\n",
    "html = browser.html\n",
    "soup = bs(html, \"html.parser\")\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting all the links for the webpage\n",
    "all_links = soup.find_all(\"a\", class_=\"itemLink product-item\")\n",
    "\n",
    "# Creating list of all URLS dictionary\n",
    "hemisphere_image_urls = []\n",
    "\n",
    "# Since every hemisphere has two equal links (one for the image and one for the title), I iterate to get only the even results: 2, 4, 6 and 8\n",
    "# On every iteration, I go into the browser and get all the results needed.\n",
    "\n",
    "# Enumerating to get iteration number\n",
    "for index, link in enumerate(all_links):\n",
    "    # Checking if iteration is even\n",
    "    if (index % 2) == 0:\n",
    "        # Entering the first link\n",
    "        browser.visit(\"https://astrogeology.usgs.gov\" + link[\"href\"])\n",
    "        \n",
    "        # Saving the html code in soup\n",
    "        html = browser.html\n",
    "        soup = bs(html, \"html.parser\")\n",
    "        \n",
    "        # I use the prefix from the webpage and add it to the find method to get the source and title\n",
    "        image = \"astrogeology.usgs.gov\" + soup.find(\"img\", class_=\"wide-image\")[\"src\"]\n",
    "        title = soup.find(\"h2\", class_=\"title\").text\n",
    "        \n",
    "        # Finally, the values are appended as a dictionary into the list\n",
    "        hemisphere_image_urls.append({\"title\":title,\"img_url\":image})\n",
    "        browser.visit(\"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkinig the resulting list\n",
    "hemisphere_image_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exiting the browser\n",
    "browser.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
